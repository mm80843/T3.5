[Home](https://github.com/mm80843/T3.5/blob/pages/index.md) >> Class: [Risk](https://github.com/mm80843/T3.5/tree/pages/docs/Risk/index.md) >> Individual ID:PBN__Risk_3508 

# __Failure to recognize biased language or unfair representation in nlp-generated insights__

## Articles mentionning the risk

* [Agade_exploring_2020](https://github.com/mm80843/T3.5/blob/pages/Article/PBN__Article_379.md)

## Mitigations of this risk

* [Diversity and bias training for nlp developers and analysts](https://github.com/mm80843/T3.5/blob/pages/Mitigation/PBN__Mitigation_5379.md)

## Name of the risk

Perpetuating stereotypes, inequality, and discrimination

## People affected by this risk

* [Marginalized groups](https://github.com/mm80843/T3.5/blob/pages/Stakeholder/PBN__Stakeholder_877.md)
* [Underrepresented communities](https://github.com/mm80843/T3.5/blob/pages/Stakeholder/PBN__Stakeholder_2736.md)

## Stakeholders who can mitigate this risk

* [Nlp development teams and diversity advocates](https://github.com/mm80843/T3.5/blob/pages/Stakeholder/PBN__Stakeholder_2737.md)

## Technologies linked to the risk

* [Natural language processing algorithms for bias detection](https://github.com/mm80843/T3.5/blob/pages/Technology/PBN__Technology_4048.md)

## This Risk belongs to this RiskGroup

* [Data privacy and security risks](https://github.com/mm80843/T3.5/blob/pages/RiskGroup/PBN__RiskGroup_4.md)

## This Risk belongs to this RiskSubgroup

* [Privacy risks](https://github.com/mm80843/T3.5/blob/pages/RiskSubgroup/PBN__RiskSubgroup_4.md)

