{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.7\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import langchain, os, openai, dotenv\n",
    "\n",
    "import re\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.embeddings import AzureOpenAIEmbeddings\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "import datetime\n",
    "\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "import chromadb\n",
    "import dotenv, time\n",
    "\n",
    "import os, glob\n",
    "from pathlib import Path\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(openai.__version__)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"./vectorDB/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6643 elements already stored.\n"
     ]
    }
   ],
   "source": [
    "vectordb = Chroma(persist_directory=base_path,embedding_function=embeddings)\n",
    "print(len(vectordb.get()[\"ids\"]),\"elements already stored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent_chain(llm):\n",
    "    chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_llm_response(query,vectordb,temperature=0.1,k=10):\n",
    "    F = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    Q = query+\",\"+str(temperature)+\",\"+str(k)\n",
    "    Q = hashlib.md5(Q.encode()).hexdigest()\n",
    "    print(Q)\n",
    "    FILE = \"cache/\"+Q+\".md\"\n",
    "    if os.path.isfile(FILE):\n",
    "        with open(FILE,\"r\") as f:\n",
    "            A =f.read()\n",
    "            answer = A.split(\"\\n\\n---\\n\\n>A:\\n\")[-1].strip()\n",
    "            docs = A.split(\"\\n\\n---\\n\\n>A:\\n\")[-2].split(\"\\n\\n---\\n\\nD:\\n\")[-1].strip()\n",
    "            docs = re.findall(\"\\'article\\': \\'(.*?)\\'}\", docs, re.DOTALL)\n",
    "    else:\n",
    "        llm = ChatOpenAI(\n",
    "            # models : https://platform.openai.com/docs/models\n",
    "            temperature=temperature,\n",
    "            model=\"gpt-3.5-turbo-1106\"\n",
    "        )\n",
    "        chain = create_agent_chain(llm)\n",
    "        matching_docs = vectordb.similarity_search(query,k)\n",
    "        answer = chain.run(input_documents=matching_docs, question=query)\n",
    "        docs = [x.metadata[\"article\"] for x in matching_docs]\n",
    "        with open(FILE,\"w\") as f:\n",
    "            f.write(\">Q:\\n\"+query +\"\\n\\n---\\n\\nD:\\n\"+str(matching_docs)+ \"\\n\\n---\\n\\n>A:\\n\"+answer)\n",
    "    return answer, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "e9742f8acc4e2fe49f1a3ee33998721c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'UV-C, or ultraviolet germicidal irradiation, is a disinfection method that uses short-wavelength ultraviolet rays to kill or inactivate microorganisms by destroying their nucleic acids and disrupting their DNA, rendering them unable to perform their cellular functions. UV-C is used in a variety of applications, such as purifying food, air, and water. It is particularly effective against airborne bacteria and viruses, including the coronavirus. UV-C radiation is typically produced by fluorescent lamps or gas discharge lamps and is used in various settings, including upper-room fixtures, air handling units, and air purification systems. UV-C radiation is known to be harmful to human skin and eyes and can accelerate the degradation of certain materials, so direct exposure to humans and sensitive materials should be avoided.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, d = get_llm_response(\"What is UV-C\",vectordb,temperature=0.1,k=10)\n",
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f79bc2406addd2c06911dc053b733d86c52c13481e10d53afee492d28d2db597"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
