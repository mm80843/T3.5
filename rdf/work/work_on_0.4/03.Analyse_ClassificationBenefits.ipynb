{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: optimized Cython parser module 'owlready2_optimized' is not available, defaulting to slower Python implementation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from owlready2 import *\n",
    "import owlready2\n",
    "print(owlready2.VERSION)\n",
    "\n",
    "import pandas as pd\n",
    "import glob, os, hashlib\n",
    "import requests, json\n",
    "from datetime import datetime\n",
    "\n",
    "import random\n",
    "\n",
    "def NOW():\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    return \"Current Time = \"+ str(current_time)\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('.env')\n",
    "\n",
    "URL = os.getenv(\"KG_URL_FCT\")\n",
    "TOK3N = os.getenv(\"KG_TOKEN\")\n",
    "\n",
    "NBCAP = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"llm\", \"../../../utils/llm.py\")\n",
    "h = importlib.util.module_from_spec(spec)\n",
    "sys.modules[\"llm\"] = h\n",
    "spec.loader.exec_module(h)\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"rdfutils\", \"../../../utils/rdfutils.py\")\n",
    "u = importlib.util.module_from_spec(spec)\n",
    "sys.modules[\"rdfutils\"] = u\n",
    "spec.loader.exec_module(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "onto = get_ontology(\"./WIP_2.owl\").load()\n",
    "u.cOnto(onto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benefits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1598, 1598)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BENEFRETURNS = [x.label[0] for x in onto.BenefReturn.instances() if len(x.label) >= 1]\n",
    "len(BENEFRETURNS),len(list(set(BENEFRETURNS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Early warning of disease outbreaks'],\n",
       " ['Improved public health response, reduced transmission, better control of outbreaks'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = list(onto.Benef.instances())[0]\n",
    "x.label,x.has_BenefReturn[0].label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_benefit(CategoriesOfBenef):\n",
    "    return [\n",
    "        {\n",
    "        \"name\": \"classify_benefits\",\n",
    "        \"description\": \"Function used to classify benefits from a high level perspective.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"sorted_benefits\": {\n",
    "                    \"type\": 'array',\n",
    "                    \"items\": {\n",
    "                        \"type\": 'object',\n",
    "                        \"description\": \"A type of benefit \",\n",
    "                        \"properties\": {\n",
    "                            \"name\" :{\n",
    "                                \"type\": 'string', \n",
    "                                \"description\": 'The benefit being considered.'\n",
    "                            },\n",
    "                            \"category\" :{\n",
    "                                \"type\": 'string', \n",
    "                                \"enum\":CategoriesOfBenef,\n",
    "                                \"description\": 'The category of benefit that matches the benefit being considered. '\n",
    "                            },\n",
    "                            \"confidence\" :{\n",
    "                                \"type\": 'string',  \n",
    "                                \"enum\":[\"High\",\"Medium-high\",\"Medium\",\"Low\"],\n",
    "                                \"description\": 'Confidence that this is the correct benefit category.'\n",
    "                            }                            \n",
    "                        },\n",
    "                        \"required\": [\"name\",'category',\"confidence\"],\n",
    "                    }\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"sorted_benefits\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT = {'Political': [\n",
    "    \"Improved Governance and Decision-Making\",\n",
    "    \"Increased Public Trust and Compliance\",\n",
    "    \"Enhanced Policy Development and Implementation\",\n",
    "    \"Economic Stability and Investment Attraction\",\n",
    "    \"Crisis Management and Public Health Response\"\n",
    "],\n",
    " 'Infrastructure': [\n",
    "    \"Operational Efficiency and Adaptability\",\n",
    "    \"Tenant Satisfaction and Attractiveness\",\n",
    "    \"Health and Safety Improvements\",\n",
    "    \"Environmental Sustainability and Green Practices\",\n",
    "    \"Economic Value and Asset Enhancement\",\n",
    "    \"Supply Chain Reliability and Market Access\",\n",
    "    \"Innovative Technologies and Research Advancements\",\n",
    "    \"Urban Resilience and Community Well-being\",\n",
    "    \"Project Management and Construction Excellence\",\n",
    "    \"Public Health and Epidemiological Contributions\"\n",
    "],\n",
    " 'Economic': [\n",
    "    \"Health and Safety Improvements\",\n",
    "    \"Asset and Property Value Enhancement\",\n",
    "    \"Operational and Supply Chain Efficiency\",\n",
    "    \"Economic Stability and Growth\",\n",
    "    \"Environmental Sustainability\",\n",
    "    \"Innovation and Investment Attraction\",\n",
    "    \"Workforce and Workplace Enhancement\",\n",
    "    \"Consumer and Market Benefits\",\n",
    "    \"Resource Management and Cost Savings\",\n",
    "    \"Social and Community Development\"\n",
    "],\n",
    " 'Legal': [\n",
    "    \"Compliance and Regulatory Adherence\",\n",
    "    \"Risk Management and Liability Reduction\",\n",
    "    \"Contractual Stability and Fair Compensation\",\n",
    "    \"Privacy Protection and Data Security\",\n",
    "    \"Crisis Management and Effective Governance\"\n",
    "],\n",
    " 'Environmental': [\n",
    "    \"Air and Water Quality Improvement\",\n",
    "    \"Energy Efficiency and Sustainability\",\n",
    "    \"Biodiversity Conservation and Ecosystem Enhancement\",\n",
    "    \"Health and Well-being Enhancement\",\n",
    "    \"Waste Management and Pollution Reduction\"\n",
    "],\n",
    " 'Technological': [\n",
    "    \"Advancement in Research and Innovation\",\n",
    "    \"Enhanced Data Security and Privacy\",\n",
    "    \"Improved Healthcare Delivery and Outcomes\",\n",
    "    \"Increased Efficiency and Productivity\",\n",
    "    \"Facilitation of Collaboration and Communication\"\n",
    "],\n",
    "'Social':[\n",
    "    \"Improved Public Health and Safety\",\n",
    "    \"Enhanced Quality of Life and Well-being\",\n",
    "    \"Increased Economic Stability and Growth\",\n",
    "    \"Strengthened Community Cohesion and Social Capital\",\n",
    "    \"Enhanced Environmental Sustainability and Access to Green Spaces\",\n",
    "    \"Improved Education and Skill Development\",\n",
    "    \"Reduced Social Inequalities and Enhanced Equity\",\n",
    "    \"Enhanced Communication and Public Awareness\",\n",
    "    \"Improved Mental Health Support and Services\",\n",
    "    \"Increased Public Trust and Confidence in Governance and Healthcare\"\n",
    "]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CategoriesOfBenef = list(DICT.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 25 items still to process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 0\n"
     ]
    }
   ],
   "source": [
    "RES = []\n",
    "NChunks = 40\n",
    "#Randomizing list\n",
    "if os.path.isfile(\"newbenef_classified_lv1.parquet.gzip\"):\n",
    "    GOOD = pd.read_parquet(\"newbenef_classified_lv1.parquet.gzip\")\n",
    "    alreadythere = GOOD[\"name\"].unique()\n",
    "    GOOD = GOOD[GOOD.name.isin(BENEFRETURNS)]\n",
    "    newRisks = [x for x in BENEFRETURNS if x not in alreadythere]\n",
    "    print(\"Starting\",len(newRisks),\"items still to process.\")\n",
    "else:\n",
    "    newRisks = BENEFRETURNS\n",
    "    GOOD = []\n",
    "    \n",
    "if len(newRisks):\n",
    "    newRisks = [str(x) for x in newRisks]\n",
    "    NB = len(newRisks)//NChunks + 1\n",
    "    CATS_FWK = [GOOD]\n",
    "    for k in range(NB)[:150]:\n",
    "        try:\n",
    "            QUESTION =  \"The benefits are:\\n\\n* \"+\"\\n* \".join(newRisks[(k*NChunks):(k+1)*NChunks]) \n",
    "            prefix =\"benefreturns_\"\n",
    "            overwrite = False\n",
    "            REQ = {\n",
    "                \"context\": \"Out the following list, classify the benefits from a high level perspective.\\n\\n\",\n",
    "                \"question\": QUESTION,\n",
    "                \"model\":\"gpt-3.5-turbo\",\n",
    "                \"functions\": classify_benefit(CategoriesOfBenef),\n",
    "                \"token\": TOK3N,\n",
    "                \"overwrite\": overwrite,\n",
    "                \"source\": \"local-evalbenefitsT3.5\",\n",
    "                \"seed\" : \"\"\n",
    "            }\n",
    "\n",
    "            H = h.hashme(REQ[\"context\"]+REQ[\"question\"])\n",
    "            cached = \"cache/\"+prefix+\"_\"+H+\".json\"\n",
    "            if not os.path.isfile(cached) or overwrite:\n",
    "                x = requests.post(URL+\"fct/\", json = REQ)\n",
    "                answer = json.loads(x.text)[\"messages\"][-1]\n",
    "                h.svt(cached,answer)\n",
    "            else:\n",
    "                answer = h.ldt(cached)\n",
    "            d = pd.DataFrame(json.loads(answer[\"function_call\"][\"arguments\"])[\"sorted_benefits\"])\n",
    "            d = d [d[\"category\"].isin(CategoriesOfBenef)]\n",
    "            if not len(GOOD):\n",
    "                CATS_FWK = d\n",
    "            else:\n",
    "                CATS_FWK.append(d)\n",
    "            DFC = pd.concat(CATS_FWK).reset_index(drop=True)\n",
    "            DFC = DFC.sort_values(by=[\"name\",\"category\"],ascending=True).drop_duplicates(subset=[\"name\"]).reset_index(drop=True)\n",
    "            DFC.to_parquet(\"newbenef_classified_lv1.parquet.gzip\",compression=\"gzip\")\n",
    "            #DFC = DFC.sort_values(by=[\"name\",\"subcategory\"],ascending=True).drop_duplicates(subset=[\"name\"]).reset_index(drop=True)\n",
    "            print(\"Done:\",k)\n",
    "        except:\n",
    "            print(\"error\")\n",
    "            pass\n",
    "else:\n",
    "    print(\"All benefs covered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checks for Benefits, round 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1577 items listed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "category\n",
       "Economic          660\n",
       "Environmental      82\n",
       "Infrastructure    226\n",
       "Legal              28\n",
       "Political          34\n",
       "Social            424\n",
       "Technological     123\n",
       "Name: name, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DFC = pd.read_parquet(\"newbenef_classified_lv1.parquet.gzip\")\n",
    "print(len(DFC),\"items listed\")\n",
    "DFC.groupby([\"category\"]).name.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFC = pd.read_parquet(\"newbenef_classified_lv1.parquet.gzip\")\n",
    "CATs = list(DFC.category.unique())\n",
    "if \"subcategory\" not in DFC.columns:\n",
    "    DFC[\"subcategory\"] = None\n",
    "if \"confidence_lv2\" not in DFC.columns:\n",
    "    DFC[\"confidence_lv2\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing Infrastructure\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "Done: 4\n",
      "Doing Technological\n",
      "error\n",
      "Done: 1\n",
      "Done: 2\n",
      "Doing Social\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n"
     ]
    }
   ],
   "source": [
    "DFC = pd.read_parquet(\"newbenef_classified_lv1.parquet.gzip\")\n",
    "CATs = list(DFC.category.unique())\n",
    "if \"subcategory\" not in DFC.columns:\n",
    "    DFC[\"subcategory\"] = None\n",
    "if \"confidence_lv2\" not in DFC.columns:\n",
    "    DFC[\"confidence_lv2\"] = None\n",
    "for CAT in CATs:\n",
    "    print(\"Doing\",CAT)\n",
    "    df = DFC[DFC.category == CAT]\n",
    "    DONE = list(df[~df.subcategory.isna()].name.unique())\n",
    "    df = df[~df.name.isin(DONE)]\n",
    "    subtechs = DICT[CAT] # classify_technology(CategoriesOfTechs)\n",
    "\n",
    "    newRisks = list(df.name)\n",
    "    RES = []\n",
    "    NChunks = 50\n",
    "\n",
    "    if len(newRisks):\n",
    "        newRisks = [str(x) for x in newRisks]\n",
    "        NB = len(newRisks)//NChunks + 1\n",
    "\n",
    "        for k in range(NB)[:NBCAP]:\n",
    "            try:\n",
    "                QUESTION =  \"The benefits are:\\n\\n* \"+\"\\n* \".join(newRisks[(k*NChunks):(k+1)*NChunks]) \n",
    "                prefix =\"benefits_\"\n",
    "                overwrite = False\n",
    "                REQ = {\n",
    "                    \"context\": \"Out the following list, classify the benefits from a high level perspective.\\n\\n\",\n",
    "                    \"question\": QUESTION,\n",
    "                    \"model\":\"gpt-3.5-turbo\",\n",
    "                    \"functions\": classify_benefit(subtechs),\n",
    "                    \"token\": TOK3N,\n",
    "                    \"overwrite\": overwrite,\n",
    "                    \"source\": \"local-evalBenefsT3.5\",\n",
    "                    \"seed\" : \"\"\n",
    "                }\n",
    "\n",
    "                H = h.hashme(REQ[\"context\"]+REQ[\"question\"])\n",
    "                cached = \"cache/\"+prefix+\"_\"+H+\".json\"\n",
    "                if not os.path.isfile(cached) or overwrite:\n",
    "                    x = requests.post(URL+\"fct/\", json = REQ)\n",
    "                    answer = json.loads(x.text)[\"messages\"][-1]\n",
    "                    h.svt(cached,answer)\n",
    "                else:\n",
    "                    answer = h.ldt(cached)\n",
    "                d = pd.DataFrame(json.loads(answer[\"function_call\"][\"arguments\"])[\"sorted_benefits\"])\n",
    "                d = d [d[\"category\"].isin(subtechs)]\n",
    "                d.columns = [\"name\",\"subcategory\",\"confidence_lv2\"]\n",
    "                for ix, row in d.iterrows():\n",
    "                    DFC.loc[DFC.name == row[\"name\"], \"subcategory\"] = row[\"subcategory\"]\n",
    "                    DFC.loc[DFC.name == row[\"name\"], \"confidence_lv2\"] = row[\"confidence_lv2\"]\n",
    "                DFC = DFC.sort_values(by=[\"name\",\"category\"],ascending=True).drop_duplicates(subset=[\"name\"]).reset_index(drop=True)\n",
    "                DFC.to_parquet(\"newbenef_classified_lv1.parquet.gzip\",compression=\"gzip\") \n",
    "                print(\"Done:\",k)\n",
    "            except:\n",
    "                print(\"error\")\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21072 items listed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "subcategory\n",
       "Access to infrastructure                              255\n",
       "Air quality and pollution effects                     243\n",
       "Artificial intelligence and machine learning risks    130\n",
       "Biodiversity and ecological impacts                   142\n",
       "Bioterrorism threats                                    3\n",
       "                                                     ... \n",
       "Wastewater and sanitation risks                       138\n",
       "Weak local decision-making mechanisms                 204\n",
       "Workforce and labor shortages                          99\n",
       "Workplace Safety and Health                             7\n",
       "Workplace safety and occupational exposure            804\n",
       "Name: name, Length: 91, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DFC = pd.read_parquet(\"newbenef_classified_lv1.parquet.gzip\")\n",
    "print(len(DFC),\"items listed\")\n",
    "DFC.groupby([\"subcategory\"]).name.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f79bc2406addd2c06911dc053b733d86c52c13481e10d53afee492d28d2db597"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
