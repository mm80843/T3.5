{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "* Owlready2 * Warning: optimized Cython parser module 'owlready2_optimized' is not available, defaulting to slower Python implementation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from owlready2 import *\n",
    "import owlready2\n",
    "print(owlready2.VERSION)\n",
    "\n",
    "import pandas as pd\n",
    "import glob, os, hashlib\n",
    "import requests, json\n",
    "from datetime import datetime\n",
    "\n",
    "import random\n",
    "\n",
    "def NOW():\n",
    "    now = datetime.now()\n",
    "    current_time = now.strftime(\"%H:%M:%S\")\n",
    "    return \"Current Time = \"+ str(current_time)\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('.env')\n",
    "\n",
    "URL = os.getenv(\"KG_URL_FCT\")\n",
    "TOK3N = os.getenv(\"KG_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import sys\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"llm\", \"../../../utils/llm.py\")\n",
    "h = importlib.util.module_from_spec(spec)\n",
    "sys.modules[\"llm\"] = h\n",
    "spec.loader.exec_module(h)\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"rdfutils\", \"../../../utils/rdfutils.py\")\n",
    "u = importlib.util.module_from_spec(spec)\n",
    "sys.modules[\"rdfutils\"] = u\n",
    "spec.loader.exec_module(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "onto = get_ontology(\"./WIP.owl\").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Techs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23090"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TECHS = [x.label[0] for x in onto.Technology.instances() if len(x.label) >= 1]\n",
    "len(TECHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_technology(CategoriesOfTechs):\n",
    "    return [\n",
    "        {\n",
    "        \"name\": \"classify_technology\",\n",
    "        \"description\": \"Function used to classify technologies from a high level perspective.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"sorted_technology\": {\n",
    "                    \"type\": 'array',\n",
    "                    \"items\": {\n",
    "                        \"type\": 'object',\n",
    "                        \"description\": \"A type of technology \",\n",
    "                        \"properties\": {\n",
    "                            \"name\" :{\n",
    "                                \"type\": 'string', \n",
    "                                \"description\": 'The technology being considered.'\n",
    "                            },\n",
    "                            \"category\" :{\n",
    "                                \"type\": 'string', \n",
    "                                \"enum\":CategoriesOfTechs,\n",
    "                                \"description\": 'The category of technology that matches the technology being considered. '\n",
    "                            },\n",
    "                            \"confidence\" :{\n",
    "                                \"type\": 'string',  \n",
    "                                \"enum\":[\"High\",\"Medium-high\",\"Medium\",\"Low\"],\n",
    "                                \"description\": 'Confidence that this is the correct technology category.'\n",
    "                            }                            \n",
    "                        },\n",
    "                        \"required\": [\"name\",'category',\"confidence\"],\n",
    "                    }\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"sorted_technology\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT = {}\n",
    "DICT[\"Air Control\"] = ['Air Filtering',\n",
    " 'Indoor Environment',\n",
    " 'HVAC Systems',\n",
    " 'Air Quality Monitoring',\n",
    " 'Air Purification',\n",
    " 'Ventilation',\n",
    " 'HEPA Filters',\n",
    " 'UV-C Disinfection']\n",
    "DICT[\"Data Analytics\"] = ['Machine Learning and AI Algorithms', 'Real-Time Data Tracking and Monitoring', 'Data Visualization and Modeling', 'Cloud-Based Data Sharing and Analysis', 'Advanced Statistical Modeling and Analysis', 'Social Media Monitoring and Analysis', 'Predictive Analytics and Modeling Tools',  'Information Dissemination Platforms']\n",
    "DICT[\"Infrastructure Management\"] = ['Sanitation and hygiene facilities', 'Ventilation and air quality systems', 'Geographic information and mapping technology', 'Healthcare infrastructure and telecommunication networks', 'Energy-efficient technologies and smart grid systems', 'Remote work tools and workforce management technologies', 'Logistics and inventory management systems', 'Capacity-building and infrastructure development tools', 'Disaster management and resilience planning technologies']\n",
    "DICT[\"Communication\"] = ['Communication and Collaboration Platforms', 'Public Awareness Campaign Tools', 'Video Conferencing and Collaboration Software', 'Social Media Platforms', 'Virtual Communication and Collaboration Technologies', 'Digital Signage and Messaging Systems', 'Multilingual Communication and Outreach Tools', 'Online Public Engagement Platforms', 'Remote Work and Telecommuting Technologies', 'Mobile App Notification Systems']\n",
    "DICT[\"Sensors and Monitoring\"] = ['Monitoring solutions', 'IoT devices', 'Surveillance systems', 'Environmental sensors', 'Sensor technologies', 'Remote monitoring tools', 'Crowd monitoring technology', 'Data collection systems', 'Real-time tracking systems']\n",
    "DICT[\"Healthcare\"] = ['Diagnostic Testing', 'Sequencing and Genomic Analysis', 'Analytical Chemistry', 'Physical Health Monitoring', 'Wellbeing and Mental Health', 'Social Distancing Technologies', 'Vaccination Development and Distribution', 'Personal Hygiene and Sanitation', 'Personal Protective Equipment (PPE)', 'Remote Healthcare and Telemedicine']\n",
    "DICT[\"Urban Planning\"] = ['Community Management Technologies', 'Spatial Planning and Layout Tools', 'Green Infrastructure Management', 'Crowd Control Solutions', 'Smart City Technologies', 'Urban Planning Solutions', 'Resilience Planning Frameworks', 'Urban Design and Mapping Tools', 'Environmental Conservation Technologies']\n",
    "DICT[\"Digital and Information Management\"] = ['Data Management', 'Web Development', 'Network Security', 'Cloud Services', 'Mobile Applications', 'Knowledge Management', 'Ontology Tools', 'Data Governance', 'Digital Infrastructure', 'Information Systems']\n",
    "DICT[\"Building design\"] = ['Building design', 'Ventilation systems', 'Home design and architecture', 'Sustainable design', 'Soundproofing technology', 'Green building strategies', 'Space optimization technologies', 'Architectural design software', 'Adaptive construction methods', 'Virtual planning and design tools']\n",
    "DICT[\"Privacy Enhancing Technologies\"] = ['Encryption and authentication', 'Biometrics and identification', 'Face and voice recognition', 'Data encryption and security', 'Cybersecurity and access control', 'Quantum cryptography', 'Ethical guidelines and advocacy', 'Fact-checking and information verification', 'Blockchain for data privacy and transparency']\n",
    "DICT[\"Building Management\"] = ['Access control and security technology', 'Lighting and daylighting systems', 'Maintenance and landscaping equipment', 'Door-locking and automatic systems', 'Operation of HVAC and ventilation systems', 'Building management and automation systems', 'Industry standard compliance tools', 'Safety and hazard detection systems']\n",
    "DICT[\"Cleaning\"] = ['Automated sanitation equipment', 'Advanced disinfection systems', 'Surface cleaning', 'Waste management technologies group', 'Sanitization equipment group', 'Disinfectant formulation', 'Self-cleaning technologies', 'Hygiene maintenance tools']\n",
    "DICT[\"Supply-chain\"] = ['Diversification and suppliers', 'Supply chain and risk management',  'Manufacturing of PPE', 'Digital supply chain management', 'Contactless delivery']\n",
    "DICT[\"Water Control\"] = ['Water and Wastewater Management', 'Water Treatment Systems', 'Water Quality Monitoring', 'Water Disinfection Solutions',  'Advanced Filtration Technologies', 'Sewage Treatment Facilities', 'Water Recycling and Conservation']\n",
    "DICT[\"Waste Management\"] = ['Recycling and waste handling technologies', 'Advanced waste sorting and processing systems', 'Smart waste handling and monitoring technologies', 'Contactless recycling and waste disposal solutions', 'Automated waste collection and segregation technologies', 'Sanitization and sterilization technologies for waste', 'Improved waste storage and disposal systems']\n",
    "\n",
    "CategoriesOfTechs = list(DICT.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doing Level 1 of technologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 0\n",
      "Done: 1\n",
      "Done: 2\n",
      "Done: 3\n",
      "Done: 4\n",
      "Done: 5\n",
      "Done: 6\n",
      "Done: 7\n",
      "Done: 8\n",
      "Done: 9\n",
      "Done: 10\n",
      "Done: 11\n",
      "Done: 12\n",
      "Done: 13\n",
      "Done: 14\n",
      "Done: 15\n",
      "Done: 16\n",
      "Done: 17\n"
     ]
    }
   ],
   "source": [
    "RES = []\n",
    "NChunks = 50\n",
    "#Randomizing list\n",
    "if os.path.isfile(\"../../support/newtechs_classified_lv1.parquet.gzip\"):\n",
    "    GOOD = pd.read_parquet(\"../../support/newtechs_classified_lv1.parquet.gzip\")\n",
    "    alreadythere = GOOD[\"name\"].unique()\n",
    "    newRisks = [x for x in TECHS if x not in alreadythere]\n",
    "    CATS_FWK = [GOOD]\n",
    "else:\n",
    "    newRisks = TECHS\n",
    "    CATS_FWK = []\n",
    "\n",
    "if len(newRisks):\n",
    "    newRisks = [str(x) for x in newRisks]\n",
    "    NB = len(newRisks)//NChunks\n",
    "\n",
    "    for k in range(NB):\n",
    "        try:\n",
    "            QUESTION =  \"The technologies are:\\n\\n* \"+\"\\n* \".join(newRisks[(k*NChunks):(k+1)*NChunks]) \n",
    "            prefix =\"technologies_\"\n",
    "            overwrite = False\n",
    "            REQ = {\n",
    "                \"context\": \"Out the following list, classify the technologies from a high level perspective.\\n\\n\",\n",
    "                \"question\": QUESTION,\n",
    "                \"functions\": classify_technology(CategoriesOfTechs),\n",
    "                \"token\": TOK3N,\n",
    "                \"overwrite\": overwrite,\n",
    "                \"source\": \"local-evalTechsT3.5\",\n",
    "                \"seed\" : \"\"\n",
    "            }\n",
    "\n",
    "            H = h.hashme(REQ[\"context\"]+REQ[\"question\"])\n",
    "            cached = \"cache/\"+prefix+\"_\"+H+\".json\"\n",
    "            if not os.path.isfile(cached) or overwrite:\n",
    "                x = requests.post(URL+\"fct/\", json = REQ)\n",
    "                answer = json.loads(x.text)[\"messages\"][-1]\n",
    "                h.svt(cached,answer)\n",
    "            else:\n",
    "                answer = h.ldt(cached)\n",
    "            d = pd.DataFrame(json.loads(answer[\"function_call\"][\"arguments\"])[\"sorted_technology\"])\n",
    "            d = d [d[\"category\"].isin(CategoriesOfTechs)]\n",
    "            CATS_FWK.append(d)\n",
    "            DFC = pd.concat(CATS_FWK).reset_index(drop=True)\n",
    "            DFC.to_parquet(\"../../support/newtechs_classified_lv1.parquet.gzip\",compression=\"gzip\")\n",
    "            print(\"Done:\",k)\n",
    "        except:\n",
    "            print(\"error\")\n",
    "            pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Doing Level 2 of technologies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>category</th>\n",
       "      <th>confidence</th>\n",
       "      <th>co```nfidence</th>\n",
       "      <th>&amp;confidence</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>confidence_lv2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nan</td>\n",
       "      <td>Privacy Enhancing Technologies</td>\n",
       "      <td>Low</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Encryption and authentication</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Floor markings</td>\n",
       "      <td>Urban Planning</td>\n",
       "      <td>Medium-high</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Spatial Planning and Layout Tools</td>\n",
       "      <td>High</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name                        category   confidence co```nfidence  \\\n",
       "0             Nan  Privacy Enhancing Technologies          Low          None   \n",
       "1  Floor markings                  Urban Planning  Medium-high          None   \n",
       "\n",
       "  &confidence                        subcategory confidence_lv2  \n",
       "0        None      Encryption and authentication            Low  \n",
       "1        None  Spatial Planning and Layout Tools           High  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DFC = pd.read_parquet(\"../../support/newtechs_classified_lv1.parquet.gzip\")\n",
    "\n",
    "DFC.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing Privacy Enhancing Technologies\n",
      "Done: 0\n",
      "Done: 1\n",
      "Doing Urban Planning\n",
      "Done: 0\n",
      "Done: 1\n",
      "Doing Healthcare\n",
      "Done: 0\n",
      "Done: 1\n",
      "Doing Communication\n",
      "Done: 0\n",
      "Done: 1\n",
      "Doing Building design\n",
      "Done: 0\n",
      "Done: 1\n",
      "Doing Water Control\n",
      "Done: 0\n",
      "Done: 1\n",
      "Doing Data Analytics\n",
      "Done: 0\n",
      "Done: 1\n",
      "Doing Infrastructure Management\n",
      "Done: 0\n",
      "Done: 1\n",
      "Doing Sensors and Monitoring\n",
      "Done: 0\n",
      "Done: 1\n",
      "Doing Building Management\n",
      "Done: 0\n",
      "Done: 1\n",
      "Doing Digital and Information Management\n",
      "Done: 0\n",
      "Done: 1\n",
      "Doing Cleaning\n",
      "Done: 0\n",
      "Done: 1\n",
      "Doing Air Control\n",
      "Done: 0\n",
      "Done: 1\n",
      "Doing Waste Management\n",
      "Done: 0\n",
      "Done: 1\n",
      "Doing Supply-chain\n",
      "Done: 0\n",
      "Done: 1\n"
     ]
    }
   ],
   "source": [
    "DFC = pd.read_parquet(\"../../support/newtechs_classified_lv1.parquet.gzip\")\n",
    "CATs = list(DFC.category.unique())\n",
    "if \"subcategory\" not in DFC.columns:\n",
    "    DFC[\"subcategory\"] = None\n",
    "if \"confidence_lv2\" not in DFC.columns:\n",
    "    DFC[\"confidence_lv2\"] = None\n",
    "for CAT in CATs:\n",
    "    print(\"Doing\",CAT)\n",
    "    df = DFC[DFC.category == CAT]\n",
    "    DONE = list(df[~df.subcategory.isna()].name.unique())\n",
    "    df = df[~df.name.isin(DONE)]\n",
    "    subtechs = DICT[CAT] # classify_technology(CategoriesOfTechs)\n",
    "\n",
    "    newRisks = list(df.name)\n",
    "    RES = []\n",
    "    NChunks = 50\n",
    "\n",
    "    if len(newRisks):\n",
    "        newRisks = [str(x) for x in newRisks]\n",
    "        NB = len(newRisks)//NChunks\n",
    "\n",
    "        for k in range(NB)[:2]:\n",
    "            try:\n",
    "                QUESTION =  \"The technologies are:\\n\\n* \"+\"\\n* \".join(newRisks[(k*NChunks):(k+1)*NChunks]) \n",
    "                prefix =\"technologies_\"\n",
    "                overwrite = False\n",
    "                REQ = {\n",
    "                    \"context\": \"Out the following list, classify the technologies from a high level perspective.\\n\\n\",\n",
    "                    \"question\": QUESTION,\n",
    "                    \"functions\": classify_technology(subtechs),\n",
    "                    \"token\": TOK3N,\n",
    "                    \"overwrite\": overwrite,\n",
    "                    \"source\": \"local-evalTechsT3.5\",\n",
    "                    \"seed\" : \"\"\n",
    "                }\n",
    "\n",
    "                H = h.hashme(REQ[\"context\"]+REQ[\"question\"])\n",
    "                cached = \"cache/\"+prefix+\"_\"+H+\".json\"\n",
    "                if not os.path.isfile(cached) or overwrite:\n",
    "                    x = requests.post(URL+\"fct/\", json = REQ)\n",
    "                    answer = json.loads(x.text)[\"messages\"][-1]\n",
    "                    h.svt(cached,answer)\n",
    "                else:\n",
    "                    answer = h.ldt(cached)\n",
    "                d = pd.DataFrame(json.loads(answer[\"function_call\"][\"arguments\"])[\"sorted_technology\"])\n",
    "                d = d [d[\"category\"].isin(subtechs)]\n",
    "                d.columns = [\"name\",\"subcategory\",\"confidence_lv2\"]\n",
    "                for ix, row in d.iterrows():\n",
    "                    DFC.loc[DFC.name == row[\"name\"], \"subcategory\"] = row[\"subcategory\"]\n",
    "                    DFC.loc[DFC.name == row[\"name\"], \"confidence_lv2\"] = row[\"confidence_lv2\"]\n",
    "                DFC.to_parquet(\"../../support/newtechs_classified_lv1.parquet.gzip\",compression=\"gzip\")\n",
    "                print(\"Done:\",k)\n",
    "            except:\n",
    "                print(\"error\")\n",
    "                pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27224 items listed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "subcategory\n",
       "Access control and security technology        12\n",
       "Adaptive construction methods                  7\n",
       "Advanced Filtration Technologies              16\n",
       "Advanced Statistical Modeling and Analysis    38\n",
       "Advanced disinfection systems                 39\n",
       "                                              ..\n",
       "Water Recycling and Conservation              13\n",
       "Water Treatment Systems                       37\n",
       "Water and Wastewater Management               74\n",
       "Web Development                               26\n",
       "Wellbeing and Mental Health                   23\n",
       "Name: name, Length: 126, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "DFC = pd.read_parquet(\"../../support/newtechs_classified_lv1.parquet.gzip\")\n",
    "print(len(DFC),\"items listed\")\n",
    "DFC.groupby([\"subcategory\"]).name.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stakeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16001"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SH = [x.label[0] for x in onto.Stakeholder.instances() if len(x.label) >= 1]\n",
    "len(SH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT = {'Health Organisations': ['Public health authorities',\n",
    "  'Occupational health and safety teams',\n",
    "  'Government health agencies ',\n",
    "  'International health organizations',\n",
    "  'Medical and healthcare personnel',\n",
    "  'Private health organisations',\n",
    "  'Mental healthcare providers',\n",
    "  'Veterinary organization'],\n",
    " 'Research Organisations': ['AI and Data analysis researchers',\n",
    "  'Research institutions ',\n",
    "  'Technology developers',\n",
    "  'Academic institutions',\n",
    "  'Data repository administrators',\n",
    "  'Local researchers',\n",
    "  'Citizen researchers',\n",
    "  'Scientific communities'],\n",
    " 'Government institutions': ['City authorities',\n",
    "  'Government departments ',\n",
    "  'Policymakers',\n",
    "  'Diplomatic bodies',\n",
    "  'Local government',\n",
    "  'Educational organizations',\n",
    "  'Political communities',\n",
    "  'Administrative authorities',\n",
    "  'Regulatory bodies ',\n",
    "  'Emergency services and management',\n",
    "  'International development agencies'],\n",
    " 'General public': ['Immigrant population',\n",
    "  'Patients',\n",
    "  'Travelers',\n",
    "  'Civil society stakeholders',\n",
    "  'Recreational and fitness enthusiasts',\n",
    "  'Visitors in indoor spaces',\n",
    "  'General population ',\n",
    "  'Digitally connected individuals',\n",
    "  'Fragile and/or isolated population',\n",
    "  'Individual with high health risks',\n",
    "  'Green spaces users '],\n",
    " 'Environmental and sustainability organizations': ['Environmental agencies',\n",
    "  'Conservation organizations',\n",
    "  'Park management stakeholders',\n",
    "  'Waste management organizations',\n",
    "  'Sustainability teams ',\n",
    "  'Energy and environmental consultants',\n",
    "  'Green area managers and organizations',\n",
    "  'Wildlife and ecosystem conservationists',\n",
    "  'Climate and sustainability research institutions'],\n",
    " 'Residents and occupants of spaces': ['Homeowners ',\n",
    "  'Building managers',\n",
    "  'People with lower income',\n",
    "  'People in high-contamination areas',\n",
    "  'Occupants of shared household spaces',\n",
    "  'Visitors to green spaces',\n",
    "  'Individuals working from home'],\n",
    " 'Workers': ['Office workers',\n",
    "  'Physical workers',\n",
    "  'Healthcare workers',\n",
    "  'Real estate agents',\n",
    "  'Facility maintenance team',\n",
    "  'AI system developers',\n",
    "  'Waste management workers',\n",
    "  'Project managers'],\n",
    " 'Regulatory bodies': ['Global governing bodies',\n",
    "  'Trade regulators',\n",
    "  'Enforcement organizations',\n",
    "  'Certification system organizations',\n",
    "  'Standardization bodies',\n",
    "  'Data governance organizations',\n",
    "  'Governments and industry regulatory bodies',\n",
    "  'Security agency',\n",
    "  'Occupational health and safety regulators',\n",
    "  'Local regulatory authorities',\n",
    "  'International trade regulators'],\n",
    " 'Public Entities': ['Sports-related organizations',\n",
    "  'Appointed personnel responsible for prevention measures',\n",
    "  'Education-related entities',\n",
    "  'Water utilities',\n",
    "  'Energy Utilities',\n",
    "  'Tourism organizations ',\n",
    "  'Culture organizations',\n",
    "  'Police ',\n",
    "  'Public communication authorities'],\n",
    " 'Financial groups': ['Banking institutions',\n",
    "  'Funding Bodies',\n",
    "  'Economic analysts and regulatory authorities',\n",
    "  'International financial institutions',\n",
    "  'Treasury departments',\n",
    "  'Small-and medium-sized enterprises',\n",
    "  'Companies in general',\n",
    "  'Global markets',\n",
    "  'Insurances providers',\n",
    "  'Finance professionals',\n",
    "  'Social entrepreneurship fund managers',\n",
    "  'Investors',\n",
    "  'Social entrepreneurship funds'],\n",
    " 'Construction and infrastructure industry': ['Building design team',\n",
    "  'Workers in the construction industry',\n",
    "  'Construction industry organizations',\n",
    "  'Contractors ',\n",
    "  'HVAC equipment providers',\n",
    "  'Site-supervision workers',\n",
    "  'Operational staff',\n",
    "  'Design and construction professionals',\n",
    "  'Building maintenance and green building professionals',\n",
    "  'Facility maintenance staff'],\n",
    " 'Manufacturing and production sector': ['Production staff',\n",
    "  'Non-medical cechnology manufacturers',\n",
    "  'Medical technology manufacturers',\n",
    "  'Food industry companies',\n",
    "  'International suppliers',\n",
    "  'Supply chain professionals',\n",
    "  'Wearable technology industry',\n",
    "  'Pharmaceutical industry'],\n",
    " 'Transportation and mobility sector': ['Logistics professionals',\n",
    "  'Ride-sharing ',\n",
    "  'City transport authorities',\n",
    "  'Vehicle users',\n",
    "  'Safe mobility',\n",
    "  'Soft mobility',\n",
    "  'Route optimization specialists',\n",
    "  'Airports',\n",
    "  'Ports',\n",
    "  'Railways',\n",
    "  'Delivery services',\n",
    "  'Logistics and transportation managers'],\n",
    " 'Cities professionals': ['City planning professionals',\n",
    "  'Urban development authorities',\n",
    "  'Individual urban planners and designers',\n",
    "  'Urban planning institutions',\n",
    "  'Smart city professionals',\n",
    "  'Sustainable city professionals',\n",
    "  'International urban institutions',\n",
    "  'Public space managers'],\n",
    " 'Retail and service industry': ['Cleaning personnel',\n",
    "  'Retail staff',\n",
    "  'Marketing agency',\n",
    "  'Local businesses',\n",
    "  'Food distribution',\n",
    "  'Animal rearing industry',\n",
    "  'Online retailers',\n",
    "  'Drive-through staff',\n",
    "  'Supermarket and health-care facility staff',\n",
    "  'Parking lot owners',\n",
    "  'Local fitness businesses'],\n",
    " 'Energy Sector': ['Energy monitoring system providers',\n",
    "  'Operators and maintenance staff ',\n",
    "  'Renewable energy investors',\n",
    "  'Energy management authorities',\n",
    "  'Energy communities',\n",
    "  'Communities reliant on the coal and oil industries',\n",
    "  'Global energy markets',\n",
    "  'Local energy markets',\n",
    "  'Energy grid operators'],\n",
    " 'Media organizations': ['Local communication experts',\n",
    "  'Individuals consuming digital content',\n",
    "  'Media and news entities',\n",
    "  'Marketing/advertising agencies',\n",
    "  'Reporter',\n",
    "  'Social media platform providers',\n",
    "  'Academic journals',\n",
    "  'News outlet'],\n",
    " 'Cities Officials': ['Municipality officials',\n",
    "  'Public building managers',\n",
    "  'City authorities ',\n",
    "  'Public space managers',\n",
    "  'Local government and urban development authorities',\n",
    "  'Community leaders',\n",
    "  'Smart city managers',\n",
    "  'Other cities departments']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_SH(CategoriesOfStakeholders):\n",
    "    return [\n",
    "        {\n",
    "        \"name\": \"classify_SH\",\n",
    "        \"description\": \"Function used to classify stakeholders from a high level perspective, based on what group they are most closely belonging to. \",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"sorted_stakeholders\": {\n",
    "                    \"type\": 'array',\n",
    "                    \"items\": {\n",
    "                        \"type\": 'object',\n",
    "                        \"description\": \"A type of stakeholder \",\n",
    "                        \"properties\": {\n",
    "                            \"name\" :{\n",
    "                                \"type\": 'string', \n",
    "                                \"description\": 'The stakeholder being considered.'\n",
    "                            },\n",
    "                            \"category\" :{\n",
    "                                \"type\": 'string', \n",
    "                                \"enum\":CategoriesOfStakeholders,\n",
    "                                \"description\": 'The category of risk that matches the stakeholder category being considered. '\n",
    "                            },\n",
    "                            \"confidence\" :{\n",
    "                                \"type\": 'string',  \n",
    "                                \"enum\":[\"High\",\"Medium-high\",\"Medium\",\"Low\"],\n",
    "                                \"description\": 'Confidence that this is the correct stakeholder category.'\n",
    "                            }                            \n",
    "                        },\n",
    "                        \"required\": [\"name\",'category',\"confidence\"],\n",
    "                    }\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"sorted_stakeholders\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: 0\n",
      "Done: 1\n",
      "Done: 2\n",
      "Done: 3\n",
      "Done: 4\n",
      "Done: 5\n",
      "Done: 6\n",
      "Done: 7\n",
      "Done: 8\n",
      "Done: 9\n",
      "Done: 10\n",
      "Done: 11\n",
      "Done: 12\n",
      "Done: 13\n",
      "Done: 14\n",
      "Done: 15\n",
      "Done: 16\n",
      "Done: 17\n",
      "Done: 18\n",
      "Done: 19\n",
      "Done: 20\n",
      "Done: 21\n",
      "Done: 22\n",
      "Done: 23\n",
      "Done: 24\n",
      "Done: 25\n",
      "Done: 26\n",
      "Done: 27\n",
      "Done: 28\n",
      "Done: 29\n",
      "Done: 30\n",
      "Done: 31\n",
      "Done: 32\n",
      "Done: 33\n",
      "Done: 34\n",
      "Done: 35\n",
      "Done: 36\n",
      "Done: 37\n",
      "Done: 38\n",
      "Done: 39\n",
      "Done: 40\n",
      "Done: 41\n",
      "Done: 42\n",
      "Done: 43\n",
      "Done: 44\n",
      "Done: 45\n",
      "Done: 46\n",
      "Done: 47\n",
      "Done: 48\n",
      "Done: 49\n",
      "Done: 50\n",
      "Done: 51\n",
      "Done: 52\n",
      "Done: 53\n",
      "Done: 54\n",
      "Done: 55\n",
      "Done: 56\n",
      "Done: 57\n",
      "Done: 58\n",
      "Done: 59\n",
      "Done: 60\n",
      "error\n",
      "Done: 62\n",
      "Done: 63\n",
      "Done: 64\n",
      "Done: 65\n",
      "Done: 66\n",
      "Done: 67\n",
      "Done: 68\n",
      "Done: 69\n",
      "Done: 70\n",
      "Done: 71\n",
      "Done: 72\n",
      "Done: 73\n",
      "Done: 74\n",
      "Done: 75\n",
      "Done: 76\n",
      "Done: 77\n",
      "Done: 78\n",
      "Done: 79\n",
      "Done: 80\n",
      "Done: 81\n",
      "Done: 82\n",
      "Done: 83\n",
      "Done: 84\n",
      "Done: 85\n",
      "Done: 86\n",
      "Done: 87\n",
      "Done: 88\n",
      "Done: 89\n",
      "Done: 90\n",
      "Done: 91\n",
      "Done: 92\n",
      "Done: 93\n",
      "Done: 94\n",
      "Done: 95\n",
      "Done: 96\n",
      "Done: 97\n",
      "Done: 98\n",
      "Done: 99\n",
      "Done: 100\n",
      "Done: 101\n",
      "Done: 102\n",
      "Done: 103\n",
      "Done: 104\n",
      "Done: 105\n",
      "Done: 106\n",
      "Done: 107\n",
      "Done: 108\n",
      "Done: 109\n",
      "Done: 110\n",
      "Done: 111\n",
      "Done: 112\n",
      "Done: 113\n",
      "Done: 114\n",
      "Done: 115\n",
      "Done: 116\n",
      "Done: 117\n",
      "Done: 118\n",
      "Done: 119\n",
      "Done: 120\n",
      "Done: 121\n",
      "Done: 122\n"
     ]
    }
   ],
   "source": [
    "CategoriesOfStakeholders = DICT.keys()\n",
    "RES = []\n",
    "NChunks = 50\n",
    "#Randomizing list\n",
    "if os.path.isfile(\"../../support/newstakeholders_classified_lv1.parquet.gzip\"):\n",
    "    GOOD = pd.read_parquet(\"../../support/newstakeholders_classified_lv1.parquet.gzip\")\n",
    "    alreadythere = GOOD[\"name\"].unique()\n",
    "    newRisks = [x for x in SH if x not in alreadythere]\n",
    "    CATS_FWK = [GOOD]\n",
    "else:\n",
    "    newRisks = SH\n",
    "    CATS_FWK = []\n",
    "if len(newRisks):\n",
    "    NB = len(newRisks)//NChunks\n",
    "    for k in range(NB):\n",
    "        try:\n",
    "            QUESTION =  \"The stakeholders are:\\n\\n* \"+\"\\n* \".join(newRisks[(k*NChunks):(k+1)*NChunks]) \n",
    "            prefix =\"sh_\"\n",
    "            overwrite = False\n",
    "            REQ = {\n",
    "                \"context\": \"Out the following list, classify the stakeholders from a high level perspective.\\n\\n\",\n",
    "                \"question\": QUESTION,\n",
    "                \"functions\": classify_SH(list(CategoriesOfStakeholders)),\n",
    "                \"token\": TOK3N,\n",
    "                \"overwrite\": overwrite,\n",
    "                \"source\": \"local-evalSHT3.5\",\n",
    "                \"seed\" : \"\"\n",
    "            }\n",
    "\n",
    "            H = h.hashme(REQ[\"context\"]+REQ[\"question\"])\n",
    "            cached = \"cache/\"+prefix+\"_\"+H+\".json\"\n",
    "            if not os.path.isfile(cached) or overwrite:\n",
    "                x = requests.post(URL+\"fct/\", json = REQ)\n",
    "                answer = json.loads(x.text)[\"messages\"][-1]\n",
    "                h.svt(cached,answer)\n",
    "            else:\n",
    "                answer = h.ldt(cached)\n",
    "            d = pd.DataFrame(json.loads(answer[\"function_call\"][\"arguments\"])[\"sorted_stakeholders\"])\n",
    "            d = d [d[\"category\"].isin(CategoriesOfStakeholders)]\n",
    "            CATS_FWK.append(d)\n",
    "            DFC = pd.concat(CATS_FWK).reset_index(drop=True)\n",
    "            DFC.to_parquet(\"../../support/newstakeholders_classified_lv1.parquet.gzip\",compression=\"gzip\")\n",
    "            print(\"Done:\",k)\n",
    "        except:\n",
    "            print(\"error\")\n",
    "            pass\n",
    "else:\n",
    "    print(\"All risks covered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10875 items listed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "category\n",
       "Cities Officials                                    70\n",
       "Cities professionals                                67\n",
       "Construction and infrastructure industry           496\n",
       "Energy Sector                                      114\n",
       "Environmental and sustainability organizations     420\n",
       "Financial groups                                   219\n",
       "General public                                    1028\n",
       "Government institutions                            820\n",
       "Health Organizations                              1573\n",
       "Manufacturing and production sector                333\n",
       "Media organizations                                159\n",
       "Private Sector                                    1175\n",
       "Public Entities                                    439\n",
       "Regulatory bodies                                  162\n",
       "Research Organisations                             801\n",
       "Residents and occupants of spaces                 2455\n",
       "Retail and service industry                        298\n",
       "Transportation and mobility sector                 246\n",
       "Name: name, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "DFC = pd.read_parquet(\"../../support/newstakeholders_classified_lv1.parquet.gzip\")\n",
    "print(len(DFC),\"items listed\")\n",
    "DFC.groupby([\"category\"]).name.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFC = pd.read_parquet(\"../../support/newstakeholders_classified_lv1.parquet.gzip\")\n",
    "CATs = list(DFC.category.unique())\n",
    "if \"subcategory\" not in DFC.columns:\n",
    "    DFC[\"subcategory\"] = None\n",
    "if \"confidence_lv2\" not in DFC.columns:\n",
    "    DFC[\"confidence_lv2\"] = None\n",
    "for CAT in CATs:\n",
    "    print(\"Doing\",CAT)\n",
    "    df = DFC[DFC.category == CAT]\n",
    "    DONE = list(df[~df.subcategory.isna()].name.unique())\n",
    "    df = df[~df.name.isin(DONE)]\n",
    "    subtechs = DICT[CAT] # classify_technology(CategoriesOfTechs)\n",
    "\n",
    "    newRisks = list(df.name)\n",
    "    RES = []\n",
    "    NChunks = 50\n",
    "\n",
    "    if len(newRisks):\n",
    "        newRisks = [str(x) for x in newRisks]\n",
    "        NB = len(newRisks)//NChunks\n",
    "\n",
    "        for k in range(NB)[:2]:\n",
    "            try:\n",
    "                QUESTION =  \"The stakeholders are:\\n\\n* \"+\"\\n* \".join(newRisks[(k*NChunks):(k+1)*NChunks]) \n",
    "                prefix =\"technologies_\"\n",
    "                overwrite = False\n",
    "                REQ = {\n",
    "                    \"context\": \"Out the following list, classify the stakeholders from a high level perspective.\\n\\n\",\n",
    "                    \"question\": QUESTION,\n",
    "                    \"functions\": classify_SH(subtechs),\n",
    "                    \"token\": TOK3N,\n",
    "                    \"overwrite\": overwrite,\n",
    "                    \"source\": \"local-evalTechsT3.5\",\n",
    "                    \"seed\" : \"\"\n",
    "                }\n",
    "\n",
    "                H = h.hashme(REQ[\"context\"]+REQ[\"question\"])\n",
    "                cached = \"cache/\"+prefix+\"_\"+H+\".json\"\n",
    "                if not os.path.isfile(cached) or overwrite:\n",
    "                    x = requests.post(URL+\"fct/\", json = REQ)\n",
    "                    answer = json.loads(x.text)[\"messages\"][-1]\n",
    "                    h.svt(cached,answer)\n",
    "                else:\n",
    "                    answer = h.ldt(cached)\n",
    "                d = pd.DataFrame(json.loads(answer[\"function_call\"][\"arguments\"])[\"sorted_technology\"])\n",
    "                d = d [d[\"category\"].isin(subtechs)]\n",
    "                d.columns = [\"name\",\"subcategory\",\"confidence_lv2\"]\n",
    "                for ix, row in d.iterrows():\n",
    "                    DFC.loc[DFC.name == row[\"name\"], \"subcategory\"] = row[\"subcategory\"]\n",
    "                    DFC.loc[DFC.name == row[\"name\"], \"confidence_lv2\"] = row[\"confidence_lv2\"]\n",
    "                DFC.to_parquet(\"../../support/newstakeholders_classified_lv1.parquet.gzip\",compression=\"gzip\")\n",
    "                print(\"Done:\",k)\n",
    "            except:\n",
    "                print(\"error\")\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20897"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "RISKS = [x.label[0] for x in onto.Risk.instances() if len(x.label) >= 1]\n",
    "len(RISKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DICT = {'Political risks': ['Trust and transparency challenges',\n",
    "  'Globalization challenges',\n",
    "  'Lack of global governance and coordination',\n",
    "  'Weak local decision-making mechanisms',\n",
    "  'Lack of coordination and consistency in mitigation measures',\n",
    "  'Ineffectiveness of interventions',\n",
    "  'Bioterrorism threats',\n",
    "  'Global coordination challenges',\n",
    "  'Lack of transparency and clarity'],\n",
    " 'Social risks': ['Disinformation and Misinformation',\n",
    "  'Social and Psychological Effects ',\n",
    "  'Social Justice Concerns',\n",
    "  'Communication and Messaging',\n",
    "  'Access to infrastructure  ',\n",
    "  'Physical activity and mobility',\n",
    "  'Misinformation and Media Risks',\n",
    "  'Cultural and Lifestyle Risks',\n",
    "  'Vulnerability risks',\n",
    "  'Occupational and Employment Risks',\n",
    "  'Mental and Emotional Wellbeing',\n",
    "  'Health Behaviors and Compliance'],\n",
    " 'Infrastructure risks': ['Inadequate remote work setup for employees',\n",
    "  'Improper architectural designs',\n",
    "  'Inadequate mobility schemes',\n",
    "  'Poor urban planning',\n",
    "  'Infrastructure maintenance risk ',\n",
    "  'Lack of emphasis on air quality ',\n",
    "  'Lack of emphasis on water quality ',\n",
    "  'Insufficient adoption of health-focused building standards',\n",
    "  'Insufficient adoption of health-focused urban standards',\n",
    "  'Inadequate hospital design ',\n",
    "  'Inadequate adaptability to emerging problems  ',\n",
    "  'Disruptions from outbreaks and other major external events'],\n",
    " 'Public health risks': ['Failure to implement preventive measures',\n",
    "  'Misinterpretation of data and results',\n",
    "  'Lack of access to health services',\n",
    "  'Public health messaging and education',\n",
    "  'Lack of effective medical solutions',\n",
    "  'Healthcare resource shortage and management',\n",
    "  'Workplace safety and occupational exposure',\n",
    "  'Poor access to Diagnostics and Treatment',\n",
    "  'Poor vector-borne diseases control'],\n",
    " 'Data Privacy and Security risks': ['Data Security risks',\n",
    "  'Privacy risks',\n",
    "  'Cybersecurity Threats',\n",
    "  'Inaccurate or Incomplete Data',\n",
    "  'Misuse of Personal Data',\n",
    "  'Reliability and Quality of Data',\n",
    "  'Surveillance and Monitoring Privacy Concerns',\n",
    "  'Limited Accessibility and Data Equity',\n",
    "  'Transparency and Accountability Issues',\n",
    "  'Potential Misinformation and False Data'],\n",
    " 'Economic risks': ['Supply chain disruptions',\n",
    "  'Pandemic impact on markets',\n",
    "  'Lower investment',\n",
    "  'Lower employment',\n",
    "  'Discontinuity of services',\n",
    "  'Global recession and economic instability',\n",
    "  'Construction industry impacts',\n",
    "  'Resource and capability risks',\n",
    "  'Workforce and labor shortages',\n",
    "  'Financial strains and liquidity crises',\n",
    "  'Food supply chain disruptions '],\n",
    " 'Legal risks': ['Compliance and Contractual',\n",
    "  'Data and Research Integrity',\n",
    "  'Intellectual Property',\n",
    "  'Workplace Safety and Health',\n",
    "  'Privacy and Civil Liberties',\n",
    "  'Fraud and Misconduct',\n",
    "  'Healthcare Legislation',\n",
    "  'Building Codes and Certification',\n",
    "  'Technology Deployment and Surveillance'],\n",
    " 'Environmental risks': ['Climate change',\n",
    "  'Pollution increase',\n",
    "  'Environmental health risks',\n",
    "  'Air quality and pollution effects',\n",
    "  'Urbanization and habitat loss',\n",
    "  'Climate change effects',\n",
    "  'Wastewater and sanitation risks',\n",
    "  'Biodiversity and ecological impacts',\n",
    "  'Energy consumption and sustainability issues'],\n",
    " 'Technological risks': ['Data privacy and security risks',\n",
    "  'Healthcare and medical risks',\n",
    "  'Infrastructure and connectivity risks',\n",
    "  'Modeling and simulation risks',\n",
    "  'Modeling and prediction risks',\n",
    "  'Artificial intelligence and machine learning risks',\n",
    "  'Inadequate ventilation and air circulation',\n",
    "  'Operational and implementation risks ',\n",
    "  'Innovation and adoption risks',\n",
    "  'Healthcare infrastructure and technology adoption risks ']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CategoriesOfRisks = list(DICT.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_risks_PESTLE(CategoriesOfRisks):\n",
    "    return [\n",
    "        {\n",
    "        \"name\": \"classify_risks_PESTLE\",\n",
    "        \"description\": \"Function used to classify risks from a high level perspective, based on what they  impact the most . \",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"sorted_risks\": {\n",
    "                    \"type\": 'array',\n",
    "                    \"items\": {\n",
    "                        \"type\": 'object',\n",
    "                        \"description\": \"A type of risk \",\n",
    "                        \"properties\": {\n",
    "                            \"name\" :{\n",
    "                                \"type\": 'string', \n",
    "                                \"description\": 'The risk being considered.'\n",
    "                            },\n",
    "                            \"category\" :{\n",
    "                                \"type\": 'string', \n",
    "                                \"enum\":CategoriesOfRisks,\n",
    "                                \"description\": 'The category of risk that matches the risk category being considered. '\n",
    "                            },\n",
    "                            \"confidence\" :{\n",
    "                                \"type\": 'string',  \n",
    "                                \"enum\":[\"High\",\"Medium-high\",\"Medium\",\"Low\"],\n",
    "                                \"description\": 'Confidence that this is the correct risk category.'\n",
    "                            }                            \n",
    "                        },\n",
    "                        \"required\": [\"name\",'category',\"confidence\"],\n",
    "                    }\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"sorted_risks\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "error\n",
      "error\n"
     ]
    }
   ],
   "source": [
    "RES = []\n",
    "NChunks = 50\n",
    "#Randomizing list\n",
    "if os.path.isfile(\"../../support/newrisks_classified_lv1.parquet.gzip\"):\n",
    "    GOOD = pd.read_parquet(\"../../support/newrisks_classified_lv1.parquet.gzip\")\n",
    "    alreadythere = GOOD[\"name\"].unique()\n",
    "\n",
    "    newRisks = [x for x in RISKS if x not in alreadythere]\n",
    "else:\n",
    "    newRisks = RISKS\n",
    "    \n",
    "if len(newRisks):\n",
    "    newRisks = [str(x) for x in newRisks]\n",
    "    NB = len(newRisks)//NChunks\n",
    "    CATS_FWK = [GOOD]\n",
    "    for k in range(NB)[:150]:\n",
    "        try:\n",
    "            QUESTION =  \"The risks are:\\n\\n* \"+\"\\n* \".join(newRisks[(k*NChunks):(k+1)*NChunks]) \n",
    "            prefix =\"risks_\"\n",
    "            overwrite = False\n",
    "            REQ = {\n",
    "                \"context\": \"Out the following list, classify the risks from a high level perspective.\\n\\n\",\n",
    "                \"question\": QUESTION,\n",
    "                \"functions\": classify_risks_PESTLE(CategoriesOfRisks),\n",
    "                \"token\": TOK3N,\n",
    "                \"overwrite\": overwrite,\n",
    "                \"source\": \"local-evalrisksT3.5\",\n",
    "                \"seed\" : \"\"\n",
    "            }\n",
    "\n",
    "            H = h.hashme(REQ[\"context\"]+REQ[\"question\"])\n",
    "            cached = \"cache/\"+prefix+\"_\"+H+\".json\"\n",
    "            if not os.path.isfile(cached) or overwrite:\n",
    "                x = requests.post(URL+\"fct/\", json = REQ)\n",
    "                answer = json.loads(x.text)[\"messages\"][-1]\n",
    "                h.svt(cached,answer)\n",
    "            else:\n",
    "                answer = h.ldt(cached)\n",
    "            d = pd.DataFrame(json.loads(answer[\"function_call\"][\"arguments\"])[\"sorted_risks\"])\n",
    "            d = d [d[\"category\"].isin(CategoriesOfRisks)]\n",
    "            CATS_FWK.append(d)\n",
    "            DFC = pd.concat(CATS_FWK).reset_index(drop=True)\n",
    "            DFC.to_parquet(\"../../support/newrisks_classified_lv1.parquet.gzip\",compression=\"gzip\")\n",
    "            print(\"Done:\",k)\n",
    "        except:\n",
    "            print(\"error\")\n",
    "            pass\n",
    "else:\n",
    "    print(\"All risks covered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "category\n",
       "Data Privacy and Security risks     204\n",
       "Economic risks                      397\n",
       "Environmental risks                 404\n",
       "Infrastructure risks                344\n",
       "Legal risks                          36\n",
       "Political risks                     161\n",
       "Public health risks                1269\n",
       "Social risks                        758\n",
       "Technological risks                 408\n",
       "Name: name, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "DFC = pd.read_parquet(\"../../support/newrisks_classified_lv1.parquet.gzip\")\n",
    "print(len(DFC),\"items listed\")\n",
    "DFC.groupby([\"category\"]).name.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFC = pd.read_parquet(\"../../support/newrisks_classified_lv1.parquet.gzip\")\n",
    "CATs = list(DFC.category.unique())\n",
    "if \"subcategory\" not in DFC.columns:\n",
    "    DFC[\"subcategory\"] = None\n",
    "if \"confidence_lv2\" not in DFC.columns:\n",
    "    DFC[\"confidence_lv2\"] = None\n",
    "for CAT in CATs:\n",
    "    print(\"Doing\",CAT)\n",
    "    df = DFC[DFC.category == CAT]\n",
    "    DONE = list(df[~df.subcategory.isna()].name.unique())\n",
    "    df = df[~df.name.isin(DONE)]\n",
    "    subtechs = DICT[CAT] # classify_technology(CategoriesOfTechs)\n",
    "\n",
    "    newRisks = list(df.name)\n",
    "    RES = []\n",
    "    NChunks = 50\n",
    "\n",
    "    if len(newRisks):\n",
    "        newRisks = [str(x) for x in newRisks]\n",
    "        NB = len(newRisks)//NChunks\n",
    "\n",
    "        for k in range(NB)[:2]:\n",
    "            try:\n",
    "                QUESTION =  \"The risks are:\\n\\n* \"+\"\\n* \".join(newRisks[(k*NChunks):(k+1)*NChunks]) \n",
    "                prefix =\"technologies_\"\n",
    "                overwrite = False\n",
    "                REQ = {\n",
    "                    \"context\": \"Out the following list, classify the risks from a high level perspective.\\n\\n\",\n",
    "                    \"question\": QUESTION,\n",
    "                    \"functions\": classify_risks_PESTLE(subtechs),\n",
    "                    \"token\": TOK3N,\n",
    "                    \"overwrite\": overwrite,\n",
    "                    \"source\": \"local-evalTechsT3.5\",\n",
    "                    \"seed\" : \"\"\n",
    "                }\n",
    "\n",
    "                H = h.hashme(REQ[\"context\"]+REQ[\"question\"])\n",
    "                cached = \"cache/\"+prefix+\"_\"+H+\".json\"\n",
    "                if not os.path.isfile(cached) or overwrite:\n",
    "                    x = requests.post(URL+\"fct/\", json = REQ)\n",
    "                    answer = json.loads(x.text)[\"messages\"][-1]\n",
    "                    h.svt(cached,answer)\n",
    "                else:\n",
    "                    answer = h.ldt(cached)\n",
    "                d = pd.DataFrame(json.loads(answer[\"function_call\"][\"arguments\"])[\"sorted_technology\"])\n",
    "                d = d [d[\"category\"].isin(subtechs)]\n",
    "                d.columns = [\"name\",\"subcategory\",\"confidence_lv2\"]\n",
    "                for ix, row in d.iterrows():\n",
    "                    DFC.loc[DFC.name == row[\"name\"], \"subcategory\"] = row[\"subcategory\"]\n",
    "                    DFC.loc[DFC.name == row[\"name\"], \"confidence_lv2\"] = row[\"confidence_lv2\"]\n",
    "                DFC.to_parquet(\"../../support/newrisks_classified_lv1.parquet.gzip\",compression=\"gzip\")\n",
    "                print(\"Done:\",k)\n",
    "            except:\n",
    "                print(\"error\")\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mitigs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22884"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = [x.label[0] for x in onto.Mitigation.instances() if len(x.label) >= 1]\n",
    "len(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interventions = [x.label[0] for x in onto.BP_Intervention.instances()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_mitigation(interventions):\n",
    "    return [\n",
    "        {\n",
    "        \"name\": \"classify_mitigation\",\n",
    "        \"description\": \"Function used to classify mitigations from a high level perspective, based on what group they are most closely belonging to. \",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"sorted_mitigations\": {\n",
    "                    \"type\": 'array',\n",
    "                    \"items\": {\n",
    "                        \"type\": 'object',\n",
    "                        \"description\": \"A type of mitigation \",\n",
    "                        \"properties\": {\n",
    "                            \"name\" :{\n",
    "                                \"type\": 'string', \n",
    "                                \"description\": 'The mitigation being considered.'\n",
    "                            },\n",
    "                            \"category\" :{\n",
    "                                \"type\": 'string', \n",
    "                                \"enum\":interventions,\n",
    "                                \"description\": 'The category of mitigation that matches the mitigation category being considered. '\n",
    "                            },\n",
    "                            \"confidence\" :{\n",
    "                                \"type\": 'string',  \n",
    "                                \"enum\":[\"High\",\"Medium-high\",\"Medium\",\"Low\"],\n",
    "                                \"description\": 'Confidence that this is the correct mitigation category.'\n",
    "                            }                            \n",
    "                        },\n",
    "                        \"required\": [\"name\",'category',\"confidence\"],\n",
    "                    }\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"sorted_mitigations\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "Done: 1\n",
      "Done: 2\n",
      "error\n",
      "error\n",
      "error\n",
      "Done: 6\n",
      "Done: 7\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "Done: 18\n",
      "error\n",
      "Done: 20\n",
      "error\n",
      "error\n",
      "Done: 23\n",
      "Done: 24\n",
      "error\n",
      "error\n",
      "error\n",
      "Done: 28\n",
      "Done: 29\n",
      "Done: 30\n",
      "error\n",
      "Done: 32\n",
      "Done: 33\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "Done: 38\n",
      "error\n",
      "error\n",
      "Done: 41\n",
      "Done: 42\n",
      "error\n",
      "Done: 44\n",
      "error\n",
      "error\n",
      "Done: 47\n",
      "error\n",
      "Done: 49\n",
      "Done: 50\n",
      "error\n",
      "error\n",
      "error\n",
      "Done: 54\n",
      "error\n",
      "Done: 56\n",
      "Done: 57\n",
      "error\n",
      "Done: 59\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "Done: 77\n",
      "error\n",
      "Done: 79\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "Done: 87\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "Done: 94\n",
      "error\n",
      "error\n",
      "error\n",
      "Done: 98\n",
      "Done: 99\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "error\n",
      "Done: 105\n",
      "error\n",
      "error\n",
      "error\n",
      "Done: 109\n",
      "error\n",
      "Done: 111\n",
      "Done: 112\n",
      "error\n",
      "error\n",
      "Done: 115\n",
      "Done: 116\n",
      "error\n",
      "error\n",
      "error\n",
      "Done: 120\n"
     ]
    }
   ],
   "source": [
    "RES = []\n",
    "NChunks = 50\n",
    "#Randomizing list\n",
    "if os.path.isfile(\"../../support/newmitigation_classified_lv1.parquet.gzip\"):\n",
    "    GOOD = pd.read_parquet(\"../../support/newmitigation_classified_lv1.parquet.gzip\")\n",
    "    alreadythere = GOOD[\"name\"].unique()\n",
    "    newRisks = [x for x in m if x not in alreadythere]\n",
    "    CATS_FWK = [GOOD]\n",
    "else:\n",
    "    newRisks = m\n",
    "    CATS_FWK = []\n",
    "if len(newRisks):\n",
    "    NB = len(newRisks)//NChunks\n",
    "    for k in range(NB)[:150]:\n",
    "        try:\n",
    "            QUESTION =  \"The mitigations are:\\n\\n* \"+\"\\n* \".join(newRisks[(k*NChunks):(k+1)*NChunks]) \n",
    "            prefix =\"sh_\"\n",
    "            overwrite = False\n",
    "            REQ = {\n",
    "                \"context\": \"Out the following list, classify the mitigations from a high level perspective.\\n\\n\",\n",
    "                \"question\": QUESTION,\n",
    "                \"functions\": classify_mitigation(interventions),\n",
    "                \"token\": TOK3N,\n",
    "                \"overwrite\": overwrite,\n",
    "                \"source\": \"local-evalMitigationsT3.5\",\n",
    "                \"seed\" : \"\"\n",
    "            }\n",
    "\n",
    "            H = h.hashme(REQ[\"context\"]+REQ[\"question\"])\n",
    "            cached = \"cache/\"+prefix+\"_\"+H+\".json\"\n",
    "            if not os.path.isfile(cached) or overwrite:\n",
    "                x = requests.post(URL+\"fct/\", json = REQ)\n",
    "                answer = json.loads(x.text)[\"messages\"][-1]\n",
    "                h.svt(cached,answer)\n",
    "            else:\n",
    "                answer = h.ldt(cached)\n",
    "            d = pd.DataFrame(json.loads(answer[\"function_call\"][\"arguments\"])[\"sorted_mitigations\"])\n",
    "            d = d [d[\"category\"].isin(interventions)]\n",
    "            CATS_FWK.append(d)\n",
    "            DFC = pd.concat(CATS_FWK).reset_index(drop=True)\n",
    "            DFC.to_parquet(\"../../support/newmitigation_classified_lv1.parquet.gzip\",compression=\"gzip\")\n",
    "            print(\"Done:\",k)\n",
    "        except:\n",
    "            print(\"error\")\n",
    "            pass\n",
    "else:\n",
    "    print(\"All mitigations covered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2222 items listed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "category\n",
       "Absorb resource shortages                                             42\n",
       "Absorb surge in service demande                                       78\n",
       "Air filtration                                                        25\n",
       "Animal vectors control                                                36\n",
       "Cleaning technologies (robots)                                        14\n",
       "Control airflows in spaces & Avoid air recirculation                  48\n",
       "Control of airflows (airtight / negative pressure)                     8\n",
       "Disinfection of air                                                   41\n",
       "Early detection                                                       80\n",
       "Ensure use of personal protection equipment                           61\n",
       "Environmental parameters control                                     214\n",
       "Facilitate transparent communication                                  61\n",
       "Greenery                                                              40\n",
       "Greywater management                                                  19\n",
       "Improve physical health                                               34\n",
       "Infection tracking / monitoring                                      194\n",
       "Introduce \"multi-use\" / modular designs                                5\n",
       "Maintenance / decontamination of building water sytems                86\n",
       "Managing drinking water safety measures                               22\n",
       "Minimize supply chain disruptions                                     27\n",
       "Monitor and control indoor air quality                                33\n",
       "Natural ventilation increase                                          52\n",
       "Occupancy control (eg separating at/risk contaminated population)     75\n",
       "Optimize users flows to prevent contamination                         30\n",
       "Outdoor spaces                                                        26\n",
       "Personal hygiene (eg handwashing)                                     30\n",
       "Prevent fake news                                                     21\n",
       "Promote verified information                                          24\n",
       "Quarantine support                                                   121\n",
       "Raising awareness                                                    264\n",
       "Selection of materials                                                25\n",
       "Separate water facilities (toilets/bathrooms for contaminated)         4\n",
       "Shift controls (occupancy control of total users)                     50\n",
       "Social activities / facilitatie social interactions                   62\n",
       "Social distancing                                                     78\n",
       "Staff training / upskilling                                           51\n",
       "Support recovery of sectors via remote work                           89\n",
       "Touchless technologies                                                14\n",
       "Use of smart/innovative air quality controls technology               32\n",
       "Wall and floors treatment                                              6\n",
       "Name: name, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "DFC = pd.read_parquet(\"../../support/newmitigation_classified_lv1.parquet.gzip\")\n",
    "print(len(DFC),\"items listed\")\n",
    "DFC.groupby([\"category\"]).name.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
